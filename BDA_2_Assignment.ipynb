{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQwhBIkRmBrbwMVAbiSQxe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adithya0503/BDA_ASSIGNMENT_2/blob/main/BDA_2_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjMniRK880Jg",
        "outputId": "75fa01d4-9a98-494b-853e-77c90428d975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+----------+--------------------+\n",
            "|         features|label|prediction|         probability|\n",
            "+-----------------+-----+----------+--------------------+\n",
            "|[6.3,3.3,6.0,2.5]|    1|       1.0|[9.09928379531368...|\n",
            "|[5.8,2.7,5.1,1.9]|    1|       1.0|[6.46539029609226...|\n",
            "+-----------------+-----+----------+--------------------+\n",
            "\n",
            "Test AUC: 1.00\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"IrisBinaryClassification\").getOrCreate()\n",
        "\n",
        "# Sample Iris data (sepal_length, sepal_width, petal_length, petal_width, species)\n",
        "data = [\n",
        "    (5.1, 3.5, 1.4, 0.2, \"setosa\"),\n",
        "    (4.9, 3.0, 1.4, 0.2, \"setosa\"),\n",
        "    (7.0, 3.2, 4.7, 1.4, \"versicolor\"),\n",
        "    (6.4, 3.2, 4.5, 1.5, \"versicolor\"),\n",
        "    (6.3, 3.3, 6.0, 2.5, \"virginica\"),\n",
        "    (5.8, 2.7, 5.1, 1.9, \"virginica\"),\n",
        "    (5.0, 3.6, 1.4, 0.2, \"setosa\"),\n",
        "    (6.9, 3.1, 5.4, 2.1, \"virginica\"),\n",
        "    (6.0, 2.2, 4.0, 1.0, \"versicolor\"),\n",
        "    (5.1, 2.5, 3.0, 1.1, \"versicolor\")\n",
        "]\n",
        "\n",
        "columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "# Binary label: Setosa -> 0, Others -> 1\n",
        "df = df.withColumn(\"label\", when(df.species == \"setosa\", 0).otherwise(1))\n",
        "\n",
        "# Assemble features\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "df_prepared = assembler.transform(df).select(\"features\", \"label\")\n",
        "\n",
        "# Split dataset\n",
        "train_data, test_data = df_prepared.randomSplit([0.7, 0.3], seed=123)\n",
        "\n",
        "# Logistic Regression model\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "model = lr.fit(train_data)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.transform(test_data)\n",
        "predictions.select(\"features\", \"label\", \"prediction\", \"probability\").show()\n",
        "\n",
        "# Evaluate model\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f\"Test AUC: {auc:.2f}\")\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QZJDAlae88ID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"InventoryClustering\").getOrCreate()\n",
        "\n",
        "# Simulated dataset: (weight_kg, volume_m3)\n",
        "data = [\n",
        "    (10.0, 0.5),\n",
        "    (12.0, 0.6),\n",
        "    (30.0, 1.2),\n",
        "    (32.0, 1.3),\n",
        "    (45.0, 2.0),\n",
        "    (48.0, 2.1),\n",
        "    (100.0, 5.5),\n",
        "    (102.0, 5.6),\n",
        "    (105.0, 5.8),\n",
        "    (110.0, 6.0),\n",
        "    (15.0, 0.7),\n",
        "    (16.0, 0.8),\n",
        "    (55.0, 2.4),\n",
        "    (60.0, 2.7),\n",
        "    (120.0, 6.5)\n",
        "]\n",
        "\n",
        "columns = [\"weight_kg\", \"volume_m3\"]\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "# Assemble features\n",
        "assembler = VectorAssembler(inputCols=columns, outputCol=\"features\")\n",
        "df_features = assembler.transform(df).select(\"features\")\n",
        "\n",
        "# KMeans clustering with 3 clusters\n",
        "kmeans = KMeans(k=3, seed=42)\n",
        "model = kmeans.fit(df_features)\n",
        "predictions = model.transform(df_features)\n",
        "\n",
        "# Show results\n",
        "predictions.show(truncate=False)\n",
        "\n",
        "# Print cluster centers\n",
        "print(\"Cluster Centers:\")\n",
        "for center in model.clusterCenters():\n",
        "    print(center)\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mqx2GuY86UF",
        "outputId": "fe1d966a-e6f2-423e-bd87-9afe492f739a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+\n",
            "|features   |prediction|\n",
            "+-----------+----------+\n",
            "|[10.0,0.5] |1         |\n",
            "|[12.0,0.6] |1         |\n",
            "|[30.0,1.2] |2         |\n",
            "|[32.0,1.3] |2         |\n",
            "|[45.0,2.0] |2         |\n",
            "|[48.0,2.1] |2         |\n",
            "|[100.0,5.5]|0         |\n",
            "|[102.0,5.6]|0         |\n",
            "|[105.0,5.8]|0         |\n",
            "|[110.0,6.0]|0         |\n",
            "|[15.0,0.7] |1         |\n",
            "|[16.0,0.8] |1         |\n",
            "|[55.0,2.4] |2         |\n",
            "|[60.0,2.7] |2         |\n",
            "|[120.0,6.5]|0         |\n",
            "+-----------+----------+\n",
            "\n",
            "Cluster Centers:\n",
            "[107.4    5.88]\n",
            "[13.25  0.65]\n",
            "[45.    1.95]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4MksEj9T9CXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"MovieRecommendation\").getOrCreate()\n",
        "\n",
        "# New dataset: user_id, movie_id, rating\n",
        "data = [\n",
        "    (1, 201, 4.0),\n",
        "    (1, 202, 3.5),\n",
        "    (1, 203, 5.0),\n",
        "    (2, 201, 5.0),\n",
        "    (2, 204, 2.5),\n",
        "    (2, 205, 3.0),\n",
        "    (3, 202, 4.0),\n",
        "    (3, 203, 4.5),\n",
        "    (3, 206, 3.0),\n",
        "    (4, 204, 4.5),\n",
        "    (4, 205, 4.0),\n",
        "    (4, 206, 5.0),\n",
        "    (5, 201, 2.0),\n",
        "    (5, 203, 3.5),\n",
        "    (5, 205, 5.0),\n",
        "]\n",
        "\n",
        "columns = [\"user_id\", \"movie_id\", \"rating\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "# Split into training and test sets\n",
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=123)\n",
        "\n",
        "# ALS model\n",
        "als = ALS(\n",
        "    userCol=\"user_id\",\n",
        "    itemCol=\"movie_id\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\",  # Drop NaNs\n",
        "    nonnegative=True,\n",
        "    implicitPrefs=False,  # Using explicit ratings\n",
        "    rank=10,\n",
        "    maxIter=10,\n",
        "    regParam=0.1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model = als.fit(train_data)\n",
        "\n",
        "# Predict ratings on test data\n",
        "predictions = model.transform(test_data)\n",
        "predictions.show()\n",
        "\n",
        "# Evaluate using RMSE\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Test RMSE: {rmse:.2f}\")\n",
        "\n",
        "# Recommend top 3 movies for each user\n",
        "user_recs = model.recommendForAllUsers(3)\n",
        "user_recs.show(truncate=False)\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IS5cdz087bH",
        "outputId": "27364a1c-c4b6-4d78-ece7-8da1db6ed4b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+------+----------+\n",
            "|user_id|movie_id|rating|prediction|\n",
            "+-------+--------+------+----------+\n",
            "|      1|     203|   5.0|   1.73391|\n",
            "|      3|     202|   4.0| 1.9175711|\n",
            "|      4|     204|   4.5|  2.062612|\n",
            "+-------+--------+------+----------+\n",
            "\n",
            "Test RMSE: 2.64\n",
            "+-------+------------------------------------------------------+\n",
            "|user_id|recommendations                                       |\n",
            "+-------+------------------------------------------------------+\n",
            "|1      |[{201, 3.950053}, {202, 3.4318361}, {206, 3.1784315}] |\n",
            "|2      |[{201, 4.802418}, {202, 4.1709914}, {206, 3.7882853}] |\n",
            "|3      |[{203, 4.351847}, {205, 3.8526382}, {206, 3.0097258}] |\n",
            "|4      |[{206, 4.8505797}, {201, 4.0603642}, {205, 4.0125313}]|\n",
            "|5      |[{205, 4.7558384}, {203, 3.509558}, {206, 3.3225448}] |\n",
            "+-------+------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}